{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b7e96d3",
   "metadata": {},
   "source": [
    "# Adding Safeguards to our Data Extraction Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e1794c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Additional Imports\n",
    "import os, json, math, time\n",
    "from yelpapi import YelpAPI\n",
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99db442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API Credentials\n",
    "with open('/Users/default.DESKTOP-0LDO0LD/.secret/yelp_api.json') as f:   #use your path here!\n",
    "    login = json.load(f)\n",
    "# Instantiate YelpAPI Variable\n",
    "yelp_api = YelpAPI(login['api-key'], timeout_s=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbe3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our API call parameters. When we want to search somthing else just change these parameters. \n",
    "LOCATION = 'NY,NY'\n",
    "TERM = 'Pizza'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80be15a9",
   "metadata": {},
   "source": [
    "## Create a results-in-progress JSON file, but only if it doesn't exist.\n",
    "\n",
    "This is the file where your results will be saved. Note: rename your JSON_FILE for different queries to prevent confusing results from other searches.\n",
    "\n",
    "We recommend you include your search terms in the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cb3ac62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Data/results_in_progress_NY_pizza.json already exists.\n"
     ]
    }
   ],
   "source": [
    "# Specifying JSON_FILE filename (can include a folder)\n",
    "# include the search terms in the filename\n",
    "JSON_FILE = \"Data/results_in_progress_NY_pizza.json\"\n",
    "\n",
    "## Check if JSON_FILE exists\n",
    "file_exists = os.path.isfile(JSON_FILE)\n",
    "\n",
    "## If it does not exist: \n",
    "if file_exists == False:\n",
    "    \n",
    "    ## CREATE ANY NEEDED FOLDERS\n",
    "    # Get the Folder Name only\n",
    "    folder = os.path.dirname(JSON_FILE)\n",
    "    ## If JSON_FILE included a folder:\n",
    "    if len(folder)>0:\n",
    "        # create the folder\n",
    "        os.makedirs(folder,exist_ok=True)\n",
    "        \n",
    "        \n",
    "    ## INFORM USER AND SAVE EMPTY LIST\n",
    "    print(f'[i] {JSON_FILE} not found. Saving empty list to file.')\n",
    "    \n",
    "    \n",
    "    # save an empty list\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump([],f)  \n",
    "# If it exists, inform user\n",
    "else:\n",
    "    print(f\"[i] {JSON_FILE} already exists.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df2319e",
   "metadata": {},
   "source": [
    "## Determine how many results are already in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13548de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 1000 previous results found.\n"
     ]
    }
   ],
   "source": [
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b50c5f",
   "metadata": {},
   "source": [
    "## Figure out how many pages of results we will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eca4ee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "YelpAPIError",
     "evalue": "VALIDATION_ERROR: Too many results requested, limit+offset must be <= 1000.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mYelpAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# use our yelp_api variable's search_query method to perform our API call\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43myelp_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mterm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTERM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m results\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\yelpapi\\yelpapi.py:234\u001b[0m, in \u001b[0;36mYelpAPI.search_query\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA valid location (parameter \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) or latitude/longitude combination \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    232\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(parameters \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m) must be provided.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEARCH_API_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dojo-env\\lib\\site-packages\\yelpapi\\yelpapi.py:282\u001b[0m, in \u001b[0;36mYelpAPI._query\u001b[1;34m(self, url, **kwargs)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# Yelp can return one of many different API errors, so check for one of them.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# The Yelp Fusion API does not yet have a complete list of errors, but this is on the TODO list; see\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;66;03m# https://github.com/Yelp/yelp-fusion/issues/95 for more info.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_json:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m YelpAPI\u001b[38;5;241m.\u001b[39mYelpAPIError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    283\u001b[0m                                                response_json[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m    285\u001b[0m \u001b[38;5;66;03m# we got a good response, so return\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_json\n",
      "\u001b[1;31mYelpAPIError\u001b[0m: VALIDATION_ERROR: Too many results requested, limit+offset must be <= 1000."
     ]
    }
   ],
   "source": [
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION, term=TERM, offset=n_results)\n",
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03870d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many results total?\n",
    "total_results = results['total']\n",
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8070b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "results_per_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ea131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import additional packages for controlling our loop\n",
    "import time, math\n",
    "\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d413e7",
   "metadata": {},
   "source": [
    "## Add this page of results to .json file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df889c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join new results with old list with extend and save to file\n",
    "previous_results.extend(results['businesses']) \n",
    "with open(JSON_FILE,'w') as f:\n",
    "     json.dump(previous_results,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02669bc",
   "metadata": {},
   "source": [
    "## Set up a progress bar in our for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbc6e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(n_pages)):\n",
    "    # adds 200 ms pause\n",
    "    time.sleep(.002) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566303f2",
   "metadata": {},
   "source": [
    "## For Loop to call each page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will cause an error because we are trying to request too many records.\n",
    "%%time\n",
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)\n",
    "    \n",
    "    # add a 200ms pause\n",
    "    # time.sleep(.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eab367b",
   "metadata": {},
   "source": [
    "We asked for too many results and that we can only get <= 1,000 results.\n",
    "\n",
    "This is the limitation of using the free tier of Yelp's API. If we were to pay a monthly fee for better access, we would not hit this limitation. \n",
    "\n",
    "Unfortunately, there is no way to adjust our calls to skip those first 1,000. So we can only ever get the same first 1,000 results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db809a14",
   "metadata": {},
   "source": [
    "# Autimate the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce94f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_file(JSON_FILE,  delete_if_exists=False):\n",
    "    ## Check if JSON_FILE exists\n",
    "    file_exists = os.path.isfile(JSON_FILE)\n",
    "    ## If it DOES exist:\n",
    "    if file_exists == True:\n",
    "        ## Check if user wants to delete if exists\n",
    "        if delete_if_exists==True:            \n",
    "            print(f\"[!] {JSON_FILE} already exists. Deleting previous file...\")\n",
    "            ## delete file and confirm it no longer exits.\n",
    "            os.remove(JSON_FILE)\n",
    "            ## Recursive call to function after old file deleted\n",
    "            create_json_file(JSON_FILE,delete_if_exists=False)\n",
    "        else:\n",
    "            print(f\"[i] {JSON_FILE} already exists.\")\n",
    "    ## If it does NOT exist:\n",
    "    else:\n",
    "        \n",
    "        ## INFORM USER AND SAVE EMPTY LIST\n",
    "        print(f\"[i] {JSON_FILE} not found. Saving empty list to new file.\")\n",
    "        \n",
    "        ## CREATE ANY NEEDED FOLDERS\n",
    "        # Get the Folder Name only\n",
    "        folder = os.path.dirname(JSON_FILE)\n",
    "        \n",
    "        ## If JSON_FILE included a folder:\n",
    "        if len(folder)>0:\n",
    "            # create the folder\n",
    "            os.makedirs(folder,exist_ok=True)\n",
    "        ## Save empty list to start the json file\n",
    "        with open(JSON_FILE,'w') as f:\n",
    "            json.dump([],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ac616",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new empty json file (exist the previous if it exists)\n",
    "create_json_file(JSON_FILE, delete_if_exists=True)\n",
    "## Load previous results and use len of results for offset\n",
    "with open(JSON_FILE,'r') as f:\n",
    "    previous_results = json.load(f)\n",
    "    \n",
    "## set offset based on previous results\n",
    "n_results = len(previous_results)\n",
    "print(f'- {n_results} previous results found.')\n",
    "# use our yelp_api variable's search_query method to perform our API call\n",
    "results = yelp_api.search_query(location=LOCATION,\n",
    "                                term=TERM,\n",
    "                               offset=n_results)\n",
    "## How many results total?\n",
    "total_results = results['total']\n",
    "## How many did we get the details for?\n",
    "results_per_page = len(results['businesses'])\n",
    "# Use math.ceil to round up for the total number of pages of results.\n",
    "n_pages = math.ceil((results['total']-n_results)/ results_per_page)\n",
    "n_pages\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04994958",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook( range(1,n_pages+1)):\n",
    "    \n",
    "    ## Read in results in progress file and check the length\n",
    "    with open(JSON_FILE, 'r') as f:\n",
    "        previous_results = json.load(f)\n",
    "    ## save number of results for to use as offset\n",
    "    n_results = len(previous_results)\n",
    "    \n",
    "    if (n_results + results_per_page) > 1000:\n",
    "        print('Exceeded 1000 api calls. Stopping loop.')\n",
    "        break\n",
    "    \n",
    "    ## use n_results as the OFFSET \n",
    "    results = yelp_api.search_query(location=LOCATION,\n",
    "                                    term=TERM, \n",
    "                                    offset=n_results)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## append new results and save to file\n",
    "    previous_results.extend(results['businesses'])\n",
    "    \n",
    "    # display(previous_results)\n",
    "    with open(JSON_FILE,'w') as f:\n",
    "        json.dump(previous_results,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfff8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final results\n",
    "final_df = pd.read_json(JSON_FILE)\n",
    "display(final_df.head(), final_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ccdf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate results\n",
    "final_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate ID's \n",
    "final_df.duplicated(subset='id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b83f514",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop duplicate ids and confirm there are no more duplicates\n",
    "final_df = final_df.drop_duplicates(subset='id')\n",
    "final_df.duplicated(subset='id').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a080721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the final results to a compressed csv\n",
    "final_df.to_csv('Data/final_results_NY_pizza.csv.gz', compression='gzip',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b6bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b46765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81f4850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5d5161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
